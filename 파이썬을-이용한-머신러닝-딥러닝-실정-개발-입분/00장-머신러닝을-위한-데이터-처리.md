# 00장 머신러닝을 위한 데이터 처리

이번 장에서는 데이터 스크레이핑으로 데이터를 수집하고 메신러닝을 수행하는 기법의 개요을 간단하게 소개합니다. 일단 간단하게 설명하면 1. 웹에서 데이터 다운로드하기 2. 데이터를 가공해서 저장하기 3. 저장된 데이터를 활용해 머신러닝 수행하기 라고 할 수 있습니다.

## 0-1. 크롤링, 스크레이핑, 머신러닝

### 인터넷의 빅데이터
빅데이터(Big Data) 는 이름 그대로 대규모 데이터의 집합을 의미합니다. 물론 데이터를 수집하는 것만으로는 어떤 의미도 없습니다. 수집한 데이터는 활용해야 가치가 생깁니다. 빋데이터라는 용어는 수집한 데이터를 분석해서 비즈니스에 활용하는 것까지를 의미합니다.

빅데이터를 분석한다는 것은 수많은 데이터에서 규칙성을 찾는 다는 것입니다. 데이터에 포함돼 있는 요소 중에서 중요한 것들을 추출하고 이를 분류해서 규칙성을 찾는 것이 일반적입니다.

최근 빅데이터라는 분야가 인기를 ㅡㄲㄹ고 있는 가장 츤 이유는 데이터를 쉽게 수집할 수 있게 됐기 때문입니다. 인터넷에 들어가면 수많은 데이터를 간단하게 수집할 수 있습니다. 또한 스마트폰의 보급과 소형 센서의 발달로 수많은 정보를 실시간으로 수집할 수 있게 됐다는 것도 중요한 이유입니다.

### 인터넷인 지식의 바다
이 책에서 일단 인터넷에서 기계적인 방법으로 데이터를 수집하는 내용을 설명합니다. 인터넷에는 다양한 데이터가 있습니다. 몇 가지 생각해봅시다.

### 블로그와 SNS - 트랜드 분석
블로그와 웹 사이트에는 매일매일 좋은 정보들이 업로드됩니다. 페이스북과 트위터 등의 SNS 가 펴지면서 IT 지식이 거의없는 사람들도 다양한 정보를 인터넷에 올릴수 있게 됐습니다. 이러한 정보를 수집하고 분석하면 다양한 트랜드를 분석할 수 있습니다.

### 인터넷 전자상거래 - 상품 데이터베이스
쿠팡, 인터파크 등의 인터넷 쇼핑몰에는 매일 수많은 상품의 데이터가 업로드됩니다. 네이버와 다음 같은 사이트에서 다양한 곳의 상품 데이터를 모아 웹 API 로 제공하므로 이를 이용하면 상품 데이터를 쉽게 활용할 수 있습니다.

### 금융 정보
인터넷에는 환율, 주식 등의 다양한 금융 정보가 있습니다. 따라서 각 국가의 환율, 주식, 금값 등을 실시간으로 추출할 수 있습니다. 이러한 정보를 정기적으로 추출해서 저장해두고 활용하면 예측 등의 활용할 수 있습니다.

### 이미지 데이터
또한 플리커, 인스타그램 같은 유명한 이미지 서비스를 활용하면 다양한 이미지 데이터를 얻을 수 있습니다. 이미지와 함께 제공되는 ㄷ크 정보 등을 활용하며 이미지의 내용을 함께 확인할 수 있답니다. 이 책에서도 이미지를 활용해 머신러닝을 수행하는 방법을 살펴봅니다.

### 행정 기관 정보 - 공개 데이터
행정 기관에서 공개하고 있는 공개 데이터도 있습니다. 예를 들어 "서울 열린 데이터 광장(http://data.seoul.go.kr)" 등을 통해 인구, 지리, 미세먼지 등의 정보를 얻을 수 있습니다. 이름처럼 공개 데이터, 열린 데이터이므로 대부분 자류롭게 활용할 수 있습니다.

### 위키 
인터넷에는 다양한 데이터가 있습니다. 세계 최대의 인터넷 사전이라고 불리는 위키피디아도 비교적 자유로은 라이선스를 가지고 있으므로 활용할 수 있습니다. 그 밖에도 한영 사전, 한일 사전, 한중 사전과 같은 언어 데이터도 찾아볼 수 있습니다.

### 저작권이 없어진 작품
또한 인터넷에는 저작권이 없어진 작품도 공개돼 있습니다. 고전 소설, 고전 그림 등은 대부분 다양하게 활용할 수 있습니다.

### 머신러닝 데이터
머신러닝에 활용할 목적으로 만들어진 데이터가 공개된 경우도 있습니다. 예를 들어 손글씨 이미지 데이터, 사람 얼굴 데이터, 강아지와 고양이 등의 동물 데이터가 있는 데 용도에 맞게 다양하게 활용할 수 있습니다.

이 처럼 인터넷에 있는 어려 정보를 조합하거나 정기적으로 확인하면 다양한 비즈니스에 활용할 수 있습니다.

### 스크레이핑, 크롤링, 데이터 가공
이 책에서는 일단 데이터를 추출하는 방법부터 가공하는 방법까지 설명합니다. 인터넷에 다양한 데이터가 있는 것은 사실이지만 이것을 알고 있다는 것만으로는 데이터를 활용할 수 없습니다. 데이터를 제대로 활용하려면 데이터를 다운로드하고 용도에 맞게 가공하는 과정이 필요합니다.

### 스크레이핑
스크레이핑(Scraping) 이란 웹사이트에 있는 특정 정보를 추출하는 기술을 의미합니다. 스크레이핑을 이용하면 웹 사이트에 있는 정보를 쉽게 수집할 수 있습니다. 

웹에 공개된 정보는 대부분 HTML 형식입니다. 이를 가져와서 데이터베이스에 저장하려면 데이터 가공이 필요합니다. 광고 등의 불필요한 정보를 제거하고 필요한 정보만 가져오려면 사이트의 구조를 분석해야 합니다. 따라서 스크레이핑이라는 기술은 웹에서 데이터를 추출하는 것뿐만아니라 그러한 구조를 분석하는 것도 포함됩니다.

또한 최근에는 로그인해야 유용한 정보에 접근할 수 있는 사이트도 많습니다. 이 경우 단순히 URL 을 알고 있는 것만으로는 유용한 정보에 접근할 수 없습니다. 따라서 제대로 스크레이핑하려면 로그인해서 필요한 웹 페이지에 접근하는 기술도 알아야 합니다.

### 크롤링
크롤링(Crawling)이란 프로그램이 웹 사이트를 정기적으로 돌며 정보를 추출하는 기술입니다. 그롤링 하는 프로그램ㅇㄹ "크롤러(Crawler)" 또는 "스파이더(Spider)" 라고 합니다.

예를 들어 검색 엔진을 구현할 때 사용하는 크롤러는 웹 사이트의 링크를 타고 돌며 웹 사이트를 돌아다닙니다. 그리고 웹 사이트의 데이터베이스에 저장합니다. 정기적으로 웹 사이트들을 돌아다니므로 항상 최신 정보를 유지할 수 있습니다. 

### 머신러능에 사용할 수 있는 데이터의 구조
수집한 데이터는 머신러닝을 사용해 다양하게 활용할 수 잇습니다. 하지만 웹에서 내려받은 HTML 데이터를 곧바로 머신러닝에 사용할 수 있는 것은 아닙니다. 데이터의 구조를 분석하고 필요한 부분만 추출하는 과정이 필요합니다.

추출한 데이터를 어떻게 저장할 것인지도 중요한 문제입니다. 머신러닝에 활용하려면 일단 다루기 쉬운 형태로 저장하는 것이 좋습니다. 그리고 데이터를 데이터베이스에 저장할 지 파일에 저장할 지등도 용도에 따라서 결정해야 합니다.

이 책에서는 다양한 데이터 세트를 활용해 머신러닝을 배웁니다. 어떤 데이터를 어떤 형태로 사용하지는 지 잘 살펴보기 바랍니다.

머신러닝에 활용되는 대표적인 형식으로는 "쉽표로 구분하는 CSV 형식의 데이터", "계층을 통해 구조화 할 수 있는 JSON, XML, YAML 형식의 데이터" 등이 있습니다. 이러한 형식에 대해 잘 알아두면 데이터를 활용할 떄 큰 도움이 됩니다.

또한 이후에 머신러닝을 다룰 때 자세히 설명하겠지만 텍스트 데이터와 이미지 파일을 아무런 처리 없이 학습기(머신러닝을 시키는 대상)에 입력할 수는 없습니다. 데이터에 어떤 특징이 있는 지 개발자가 직접 확인하고 가공해야 학습시킬수 있습니다.

**정리**
이 책에서는 다음과 같은 순서로 머신러닝에 대해 설펴봅니다.
⬅️ 웹에서 데이터를 다운로드합니다.(1, 2장)
⬅️ 다운로드한 데이터에서 필요한 데이터를 추출합니다.
⬅️ 추출한 데이터를 목적에 맞는 형식으로 저장합니다.(3장)
⬅️ 머신러닝을 수행합니다.(4장 이후의 내용)
